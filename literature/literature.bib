@online{lido,
	date = {08-11-2022},
	title = {LiDO3},
	url = {https://www.lido.tu-dortmund.de/cms/de/LiDO3/LiDO3_first_contact_handout.pdf},
}

@book{FoundationsDeepRL,
  title={Foundations of Deep Reinforcement Learning: Theory and Practice in Python},
  author={Graesser, L. and Keng, W.L.},
  isbn={9780135172483},
  series={Addison-Wesley Data \& Analytics Series},
  year={2019},
  publisher={Pearson Education}
}

@book{deepRL-2020,
 title={Deep Reinforcement Learning: Fundamentals, Research, and Applications},
 editor={Hao Dong, Zihan Ding, Shanghang Zhang},
 author={Hao Dong and Zihan Ding and Shanghang Zhang and Hang Yuan and Hongming Zhang and Jingqing Zhang and Yanhua Huang and Tianyang Yu and Huaqing Zhang and Ruitong Huang},
 publisher={Springer Nature},
 note={\url{http://www.deepreinforcementlearningbook.org}},
 year={2020}
}

@article{PPOPaper,
  author    = {John Schulman and
               Filip Wolski and
               Prafulla Dhariwal and
               Alec Radford and
               Oleg Klimov},
  title     = {Proximal Policy Optimization Algorithms},
  journal   = {CoRR},
  volume    = {abs/1707.06347},
  year      = {2017},
  url       = {http://arxiv.org/abs/1707.06347},
  eprinttype = {arXiv},
  eprint    = {1707.06347},
  timestamp = {Mon, 13 Aug 2018 16:47:34 +0200},
  biburl    = {https://dblp.org/rec/journals/corr/SchulmanWDRK17.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org}
}

@misc{mlAgents,
  title = {mlAgents: Documentation},
  howpublished = {\url{https://github.com/Unity-Technologies/ml-agents/tree/main/docs}},
  note = {Accessed: 21-09-2022}
}

@misc{mlAgentsIntroduction,
  title = {Introducing: Unity Machine Learning Agents Toolkit},
  howpublished = {\url{https://blog.unity.com/technology/introducing-unity-machine-learning-agents}},
  author = {Arthur Juliani},
  note = {Accessed: 21-09-2022}
}

@misc{neroRL,
  title = {neroRL: Documentation},
  howpublished = {\url{https://github.com/MarcoMeter/neroRL/tree/master/docs}},
  note = {Accessed: 21-09-2022}
}

@misc{walkerEnv,
  title = {mlAgents: Beispiel Umgebungen},
  howpublished = {\url{https://github.com/Unity-Technologies/ml-agents/blob/main/docs/Learning-Environment-Examples.md}},
  note = {Accessed: 24-09-2022}
}

@misc{gaePaper,
  doi = {10.48550/ARXIV.1506.02438},
  
  url = {https://arxiv.org/abs/1506.02438},
  
  author = {Schulman, John and Moritz, Philipp and Levine, Sergey and Jordan, Michael and Abbeel, Pieter},
  
  keywords = {Machine Learning (cs.LG), Robotics (cs.RO), Systems and Control (eess.SY), FOS: Computer and information sciences, FOS: Computer and information sciences, FOS: Electrical engineering, electronic engineering, information engineering, FOS: Electrical engineering, electronic engineering, information engineering},
  
  title = {High-Dimensional Continuous Control Using Generalized Advantage Estimation},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

@misc{trpoPaper,
  doi = {10.48550/ARXIV.1502.05477},
  
  url = {https://arxiv.org/abs/1502.05477},
  
  author = {Schulman, John and Levine, Sergey and Moritz, Philipp and Jordan, Michael I. and Abbeel, Pieter},
  
  keywords = {Machine Learning (cs.LG), FOS: Computer and information sciences, FOS: Computer and information sciences},
  
  title = {Trust Region Policy Optimization},
  
  publisher = {arXiv},
  
  year = {2015},
  
  copyright = {arXiv.org perpetual, non-exclusive license}
}

